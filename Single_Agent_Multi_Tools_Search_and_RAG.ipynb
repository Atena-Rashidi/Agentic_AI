{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e184cf",
   "metadata": {},
   "source": [
    "### 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1dfb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, requests, os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "from ias_openai_langchain import IASOpenaiConversationalLLM, IASOpenaiEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# tools\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "\n",
    "#!pip install pypdf\n",
    "#!pip install langchain-chroma --upgrade\n",
    "# !pip install chromadb\n",
    "# or\n",
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92546d04",
   "metadata": {},
   "source": [
    "### 2. Initialize the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatOpenAI('gpt-4o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a7610b",
   "metadata": {},
   "source": [
    "### 3. Tools implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f367d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'LangGraph Glossary - GitHub Pages',\n",
       "  'url': 'https://langchain-ai.github.io/langgraph/concepts/low_level/',\n",
       "  'content': 'In LangGraph, nodes are typically python functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a \"config\", containing optional configurable parameters (such as a thread_id).\\nSimilar to NetworkX, you add these nodes to a graph using the add_node method:\\n[](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-7-1)fromlangchain_core.runnablesimport RunnableConfig [...] LangGraph GlossaryÂ¶\\nGraphsÂ¶\\nAt its core, LangGraph models agent workflows as graphs. You define the behavior of your agents using three key components:\\n\\n\\nState: A shared data structure that represents the current snapshot of your application. It can be any Python type, but is typically a TypedDict or Pydantic BaseModel.\\n\\n\\nNodes: Python functions that encode the logic of your agents. They receive the current State as input, perform some computation or side-effect, and return an updated State. [...] By composing Nodes and Edges, you can create complex, looping workflows that evolve the State over time. The real power, though, comes from how LangGraph manages that State. To emphasize: Nodes and Edges are nothing more than Python functions - they can contain an LLM or just good ol\\' Python code.\\nIn short: nodes do the work. edges tell what to do next.',\n",
       "  'score': 0.8995547},\n",
       " {'title': 'A Comprehensive Guide About Langgraph: Code Included - Ionio',\n",
       "  'url': 'https://www.ionio.ai/blog/a-comprehensive-guide-about-langgraph-code-included',\n",
       "  'content': 'Now letâ€™s take a look at each component of langgraph in detail ðŸš€\\nNodes\\nA node can be any function or tool your agent uses in langgraph and these nodes are connected with other nodes using edges. Every workflow ends with a â€œENDâ€ node in langgraph which shows the end of workflow. You also need to define a starting node which will be the starting point of your workflow. Optionally, you can also define an ending node if you know the ending point of your workflow.',\n",
       "  'score': 0.8991304}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tool1: implemet Taviliy search tool\n",
    "#-----------------------------------------\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"...\"\n",
    "tavily_tool = TavilySearchResults(max_results=2)\n",
    "tavily_tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8ddc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snippet: Prolonged Periods of Unsettled Weather into Early Next Week. Showers and thunderstorms with heavy rainfall, with a few thunderstorms being severe, are expected over portions of the Southeast and Mid-Atlantic States through Monday. ... San Francisco CA 37.77Â°N 122.41Â°W (Elev. 131 ft) Last Update: 3:03 pm PDT May 3, 2025. Forecast Valid: 8pm ..., title: National Weather Service, link: https://forecast.weather.gov/MapClick.php?textField1=37.784444&textField2=-122.403333, snippet: Currently, in San Francisco, expect winds and a partly cloudy afternoon. The temperature is a breezy 60.8Â°F, and the feels-like temperature is appraised at a refreshing 57.2Â°F. The current temperature is the maximum expected temperature of the day., title: Weather today - San Francisco, CA, link: https://www.weather-atlas.com/en/california-usa/san-francisco'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tool2: implment web_search_tool\n",
    "#-----------------------------------------\n",
    "# !pip install -U duckduckgo-search\n",
    "web_search_tool = DuckDuckGoSearchResults(num_results = 2)\n",
    "web_search_tool.invoke(\"Give me the temprature in San Fransisco?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a4ee2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool3: RAG tool\n",
    "#-----------------------------------------\n",
    "# 1. Load the doc, 2. Split/Chunk the doc, 3. Vector emnedding and save in vector DB \n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from typing import List\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d17dbc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load document\n",
    "def load_documnet(folder_path: str) -> List[Document]:\n",
    "    document = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith(\"pdf\"):\n",
    "            loader = PyPDFLoader(file_path=file_path)\n",
    "        elif filename.endswith(docx):\n",
    "            loader = Docx2txtLoader(file_path=file_path)\n",
    "        else:\n",
    "            print(\"Unsupported File!\")\n",
    "        document.extend(loader.load())\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645846d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path\n",
    "folder_path = \"./docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0439910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 13\n"
     ]
    }
   ],
   "source": [
    "documents = load_documnet(folder_path = folder_path)\n",
    "print(f\"Number of Documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "813fb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Chunk the doc\n",
    "from langchain_text_splitters  import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Vector embedding and store in vector DB -> Chroma DB\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "282aee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector store\n",
    "embedding_vectore_store = Chroma.from_documents(\n",
    "    collection_name=\"my_collection\",\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a8e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic RAG Tool Schema\n",
    "class RagToolSchema(BaseModel):\n",
    "    question: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1a8ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement RAG tool\n",
    "@tool(args_schema= RagToolSchema)\n",
    "\n",
    "# create retriver tool\n",
    "# ------------------------------------\n",
    "def retriver_tool(question: str):\n",
    "    \"\"\"\n",
    "    Tool to retrive semantically similar documents to answer \n",
    "    related questions related to a company's leave policy\n",
    "    \"\"\"\n",
    "\n",
    "    retiviver = embedding_vectore_store.as_retriever(search_kwargs = {\"k\": 2})\n",
    "    retiviver_result = retiviver.invoke(question)\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in retiviver_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "ret = embedding_vectore_store.as_retriever(search_kwargs = {\"k\": 2})\n",
    "ret.invoke(\"what is the leave policy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "498655ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bind the tools with LLM\n",
    "tools = [tavily_tool, web_search_tool, retriver_tool]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d1556",
   "metadata": {},
   "source": [
    "### 4. Graph implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e999345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph \n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import add_messages\n",
    "# from langgraph.prebuilt import ToolNode --> did from scratch\n",
    "# from langgraph.prebuilt import tools_condition --> did from scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b93f9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5b78297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent node or chatbot node\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aca994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21534319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tool node\n",
    "tool_node = BasicToolNode(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1853c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a48e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat graph\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "159ffda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1a629ab23c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add all nodes to the graph\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node('tools', tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9ef9c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1a629ab23c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect agents and tools using edge and conditional edge\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c646a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the graph\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef06162c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0db6410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fed19e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat comp payload - what is AutoGenBench in machine learning?\n",
      "Assistant: AutoGenBench is a tool used in machine learning to automatically generate benchmark datasets. It is designed to help researchers and practitioners evaluate and compare the performance of different machine learning algorithms. The tool uses a variety of techniques to generate synthetic datasets that mimic the characteristics of real-world data, allowing for a more comprehensive and robust evaluation of machine learning models.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
